name: Performance Benchmarks

on:
  push:
    branches: [main]
    paths:
      - 'test/benchmarks/**'
      - 'src/**'
      - 'pixi.toml'
      - 'flake.nix'
      - 'nix/**'
  pull_request:
    branches: [main]
    paths:
      - 'test/benchmarks/**'
      - 'src/**'
      - 'flake.nix'
      - 'nix/**'
  workflow_dispatch:
  schedule:
    # Run benchmarks weekly on Sunday at 2 AM UTC
    - cron: '0 2 * * 0'

permissions:
  contents: write
  pull-requests: write

env:
  NIXPKGS_ALLOW_UNFREE: "1"

jobs:
  # ===========================================
  # Nix Evaluation Benchmarks
  # ===========================================
  nix-eval-benchmark:
    name: Nix Evaluation Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Install Nix
        uses: DeterminateSystems/nix-installer-action@v21

      - name: Setup Nix cache
        uses: DeterminateSystems/magic-nix-cache-action@v13

      - name: Benchmark flake evaluation
        id: eval-benchmark
        run: |
          echo "## Nix Evaluation Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Operation | Time (s) | Target (s) | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|----------|------------|--------|" >> $GITHUB_STEP_SUMMARY

          # Benchmark flake show
          START=$(date +%s.%N)
          nix flake show --no-write-lock-file > /dev/null 2>&1
          END=$(date +%s.%N)
          FLAKE_SHOW=$(echo "$END - $START" | bc)
          if (( $(echo "$FLAKE_SHOW < 10" | bc -l) )); then
            echo "| flake show | $FLAKE_SHOW | 10 | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| flake show | $FLAKE_SHOW | 10 | :x: |" >> $GITHUB_STEP_SUMMARY
          fi

          # Benchmark minimal shell eval
          START=$(date +%s.%N)
          nix eval .#devShells.x86_64-linux.minimal --apply 'x: x.name' > /dev/null 2>&1
          END=$(date +%s.%N)
          MINIMAL=$(echo "$END - $START" | bc)
          if (( $(echo "$MINIMAL < 5" | bc -l) )); then
            echo "| minimal shell | $MINIMAL | 5 | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| minimal shell | $MINIMAL | 5 | :x: |" >> $GITHUB_STEP_SUMMARY
          fi

          # Benchmark default shell eval
          START=$(date +%s.%N)
          nix eval .#devShells.x86_64-linux.default --apply 'x: x.name' > /dev/null 2>&1
          END=$(date +%s.%N)
          DEFAULT=$(echo "$END - $START" | bc)
          if (( $(echo "$DEFAULT < 15" | bc -l) )); then
            echo "| default shell | $DEFAULT | 15 | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| default shell | $DEFAULT | 15 | :x: |" >> $GITHUB_STEP_SUMMARY
          fi

          # Save results for artifact
          echo "flake_show=$FLAKE_SHOW" >> $GITHUB_OUTPUT
          echo "minimal_shell=$MINIMAL" >> $GITHUB_OUTPUT
          echo "default_shell=$DEFAULT" >> $GITHUB_OUTPUT

          # Create JSON for comparison
          cat > nix-eval-results.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "benchmarks": [
              {"name": "flake_show", "time": $FLAKE_SHOW, "target": 10},
              {"name": "minimal_shell", "time": $MINIMAL, "target": 5},
              {"name": "default_shell", "time": $DEFAULT, "target": 15}
            ]
          }
          EOF

      - name: Upload Nix eval benchmark results
        uses: actions/upload-artifact@v6
        with:
          name: nix-eval-benchmark-results
          path: nix-eval-results.json
          retention-days: 90

  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Install Pixi
        uses: prefix-dev/setup-pixi@v0.9.3
        with:
          pixi-version: latest

      - name: Install dependencies
        run: |
          pixi install --frozen || pixi install
          pip install pytest pytest-benchmark

      - name: Run benchmarks
        run: |
          pixi run pytest test/benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-columns=mean,stddev,min,max,rounds \
            -v || echo "Some benchmarks may have skipped (ROS2 not available)"

      - name: Store benchmark results
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: ROS2 Performance Benchmarks
          tool: 'pytest'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false
          alert-comment-cc-users: '@FlexNetOS/ros2-team'

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 90

  compare-benchmarks:
    name: Compare with Baseline
    runs-on: ubuntu-latest
    needs: benchmark
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Download current results
        uses: actions/download-artifact@v7
        with:
          name: benchmark-results
          path: ./current

      - name: Compare and comment
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');

            // Read current results
            let current = {};
            try {
              current = JSON.parse(fs.readFileSync('./current/benchmark-results.json', 'utf8'));
            } catch (e) {
              console.log('No benchmark results found');
              return;
            }

            // Format benchmark table
            let table = '## Benchmark Results\n\n';
            table += '| Test | Mean | Std Dev | Min | Max |\n';
            table += '|------|------|---------|-----|-----|\n';

            if (current.benchmarks) {
              for (const bench of current.benchmarks) {
                table += `| ${bench.name} | ${bench.stats.mean.toFixed(4)}s | ${bench.stats.stddev.toFixed(4)}s | ${bench.stats.min.toFixed(4)}s | ${bench.stats.max.toFixed(4)}s |\n`;
              }
            }

            // Post comment
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: table
            });
