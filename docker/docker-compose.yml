# =============================================================================
# FlexStack Unified Docker Compose with Profiles
# =============================================================================
# This is the main entry point for running FlexStack services with profiles.
#
# Profiles:
#   core          - Essential infrastructure (Redis, shared PostgreSQL)
#   observability - Monitoring stack (Prometheus, Grafana, Loki, Tempo)
#   ai            - AI/ML services (LocalAI, AGiXT, TensorZero)
#   identity      - Identity & secrets (Keycloak, Vault, Step-CA)
#   data          - Data services (Neo4j, MindsDB)
#   edge          - API gateway (Kong, AgentGateway)
#   messaging     - Event bus & workflows (NATS, Temporal)
#   automation    - Workflow automation (n8n, OPA)
#   full          - All services
#
# Usage:
#   # Start with specific profiles
#   docker compose --profile core --profile ai up -d
#
#   # Start development stack (core + ai)
#   docker compose --profile dev up -d
#
#   # Start full stack
#   docker compose --profile full up -d
#
#   # Or use the helper script
#   ./scripts/flexstack.sh up --profile ai
#
# See docs/DOCKER_PROFILES.md for detailed profile documentation.
# =============================================================================

name: flexstack

# =============================================================================
# CORE INFRASTRUCTURE (Profile: core, dev, full)
# Essential services required by most other services
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # Shared PostgreSQL - Primary database for multiple services
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:17.2-alpine
    container_name: flexstack-postgres
    profiles: ["core", "dev", "full"]
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      POSTGRES_MULTIPLE_DATABASES: keycloak,temporal,n8n,mindsdb,mlflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-multi-db.sh:/docker-entrypoint-initdb.d/init-multi-db.sh:ro
    ports:
      - "5432:5432"
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    labels:
      com.flexstack.profile: "core"
      com.flexstack.priority: "1"
      com.flexstack.description: "Shared PostgreSQL database"

  # ---------------------------------------------------------------------------
  # Redis - Cache & State Management
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7.4-alpine
    container_name: flexstack-redis
    profiles: ["core", "dev", "full"]
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 256M
    labels:
      com.flexstack.profile: "core"
      com.flexstack.priority: "1"
      com.flexstack.description: "Redis cache and state store"

  # ---------------------------------------------------------------------------
  # MinIO - S3-compatible Object Storage
  # ---------------------------------------------------------------------------
  minio:
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z
    container_name: flexstack-minio
    profiles: ["core", "dev", "full"]
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    labels:
      com.flexstack.profile: "core"
      com.flexstack.priority: "1"
      com.flexstack.description: "S3-compatible object storage"

  # ---------------------------------------------------------------------------
  # MinIO Initialization - Creates required buckets
  # ---------------------------------------------------------------------------
  minio-init:
    image: minio/mc:RELEASE.2025-08-13T08-35-41Z
    container_name: flexstack-minio-init
    profiles: ["core", "dev", "full"]
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
        mc alias set local http://minio:9000 $${MINIO_ROOT_USER:-minioadmin} $${MINIO_ROOT_PASSWORD:-minioadmin};
        mc mb --ignore-existing local/flexstack-artifacts;
        mc mb --ignore-existing local/flexstack-models;
        mc mb --ignore-existing local/flexstack-logs;
        mc mb --ignore-existing local/agixt;
        mc anonymous set download local/flexstack-models;
        echo 'MinIO buckets initialized';
        exit 0;
      "
    networks:
      - flexstack-network
    labels:
      com.flexstack.profile: "core"
      com.flexstack.init: "true"

# =============================================================================
# OBSERVABILITY (Profile: observability, full)
# Monitoring, logging, and tracing
# =============================================================================

  # ---------------------------------------------------------------------------
  # Prometheus - Metrics collection
  # ---------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: flexstack-prometheus
    profiles: ["observability", "full"]
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-remote-write-receiver'
    ports:
      - "9090:9090"
    volumes:
      - ../manifests/observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 512M
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # Grafana - Visualization
  # ---------------------------------------------------------------------------
  grafana:
    image: grafana/grafana:11.4.0
    container_name: flexstack-grafana
    profiles: ["observability", "full"]
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ../manifests/observability/grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      prometheus:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "3"

  # ---------------------------------------------------------------------------
  # Loki - Log aggregation
  # ---------------------------------------------------------------------------
  loki:
    image: grafana/loki:3.3.2
    container_name: flexstack-loki
    profiles: ["observability", "full"]
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ../manifests/observability/loki.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # Promtail - Log shipper
  # ---------------------------------------------------------------------------
  promtail:
    image: grafana/promtail:3.3.2
    container_name: flexstack-promtail
    profiles: ["observability", "full"]
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ../manifests/observability/promtail.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - loki
    networks:
      - flexstack-network
    restart: unless-stopped
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "3"

  # ---------------------------------------------------------------------------
  # Tempo - Distributed tracing
  # ---------------------------------------------------------------------------
  tempo:
    image: grafana/tempo:2.7.2
    container_name: flexstack-tempo
    profiles: ["observability", "full"]
    command: -config.file=/etc/tempo/tempo.yaml
    ports:
      - "3200:3200"
      - "4317:4317"
      - "4318:4318"
    volumes:
      - ../config/tempo/tempo.yaml:/etc/tempo/tempo.yaml:ro
      - tempo_data:/tmp/tempo
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3200/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # Alertmanager - Alert routing
  # ---------------------------------------------------------------------------
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: flexstack-alertmanager
    profiles: ["observability", "full"]
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    volumes:
      - ../manifests/observability/alertmanager.yml:/etc/alertmanager/config.yml:ro
      - alertmanager_data:/alertmanager
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "3"

  # ---------------------------------------------------------------------------
  # Node Exporter - Host metrics
  # ---------------------------------------------------------------------------
  node-exporter:
    image: prom/node-exporter:v1.8.2
    container_name: flexstack-node-exporter
    profiles: ["observability", "full"]
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - flexstack-network
    restart: unless-stopped
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # cAdvisor - Container metrics
  # ---------------------------------------------------------------------------
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.51.0
    container_name: flexstack-cadvisor
    profiles: ["observability", "full"]
    ports:
      - "8085:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    # Security: Minimize privileges (was: privileged: true)
    # Required capabilities for cAdvisor
    cap_add:
      - SYS_PTRACE  # For process monitoring
      - SYS_ADMIN   # For filesystem access
    # Alternative: Use specific mounts instead of full privileged access
    # privileged: true  # DISABLED for security
    networks:
      - flexstack-network
    restart: unless-stopped
    labels:
      com.flexstack.profile: "observability"
      com.flexstack.priority: "3"

# =============================================================================
# AI/ML SERVICES (Profile: ai, dev, full)
# Inference, orchestration, and ML operations
# =============================================================================

  # ---------------------------------------------------------------------------
  # LocalAI - Local LLM inference (CPU)
  # ---------------------------------------------------------------------------
  localai:
    image: localai/localai:v2.24.2-aio-cpu
    container_name: flexstack-localai
    profiles: ["ai", "dev", "full"]
    environment:
      # AIO entrypoint downloads/preloads the configured model YAMLs on first run.
      # Keep the default set minimal so the stack becomes healthy quickly.
      - PROFILE=${LOCALAI_PROFILE:-cpu}
      - MODELS=${LOCALAI_MODELS:-/localai-config/text-small.yaml,/aio/cpu/embeddings.yaml}
      - THREADS=${LOCALAI_THREADS:-4}
      - CONTEXT_SIZE=${LOCALAI_CONTEXT_SIZE:-2048}
      - PARALLEL=${LOCALAI_PARALLEL:-2}
      - F16=true
      - MODELS_PATH=/models
      - DEBUG=${LOCALAI_DEBUG:-false}
      - LOCALAI_MMAP=true
    ports:
      - "8080:8080"
    volumes:
      - ./config/localai:/localai-config:ro
      - localai_models:/models
      - localai_images:/tmp/generated/images
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 10m
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    labels:
      com.flexstack.profile: "ai"
      com.flexstack.priority: "2"
      com.flexstack.gpu: "optional"

  # ---------------------------------------------------------------------------
  # AGiXT API - Agent orchestration
  # ---------------------------------------------------------------------------
  agixt:
    image: joshxt/agixt:main
    container_name: flexstack-agixt
    profiles: ["ai", "full"]
    environment:
      AGIXT_API_KEY: ${AGIXT_API_KEY:-agixt-dev-key}
      AGIXT_URI: http://agixt:7437
      UVICORN_WORKERS: ${UVICORN_WORKERS:-4}
      DB_CONNECTED: "true"
      DATABASE_TYPE: postgresql
      DATABASE_NAME: agixt
      DATABASE_USER: ${POSTGRES_USER:-postgres}
      DATABASE_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      DATABASE_HOST: postgres
      DATABASE_PORT: 5432
      USING_S3: "true"
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      S3_BUCKET: agixt
      S3_ENDPOINT_URL: http://minio:9000
      OPENAI_API_BASE: http://localai:8080/v1
      OPENAI_API_KEY: ${OPENAI_API_KEY:-sk-localai}
      DEFAULT_PROVIDER: openai
    ports:
      - "7437:7437"
    volumes:
      - agixt_models:/agixt/models
      - agixt_workspace:/agixt/WORKSPACE
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
      localai:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7437/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '4.0'
        reservations:
          memory: 1G
    labels:
      com.flexstack.profile: "ai"
      com.flexstack.priority: "3"

  # ---------------------------------------------------------------------------
  # AGiXT Interactive UI
  # ---------------------------------------------------------------------------
  agixt-ui:
    image: joshxt/agixt-interactive:main
    container_name: flexstack-agixt-ui
    profiles: ["ui", "full"]
    environment:
      AGIXT_SERVER: http://agixt:7437
      AGIXT_API_KEY: ${AGIXT_API_KEY:-agixt-dev-key}
    ports:
      - "3437:3437"
    depends_on:
      - agixt
    networks:
      - flexstack-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
    labels:
      com.flexstack.profile: "ai"
      com.flexstack.priority: "4"

  # ---------------------------------------------------------------------------
  # MindsDB - AI/ML Database Layer
  # ---------------------------------------------------------------------------
  mindsdb:
    image: mindsdb/mindsdb:25.14.0
    container_name: flexstack-mindsdb
    profiles: ["ai", "data", "full"]
    environment:
      MINDSDB_STORAGE_DIR: /mindsdb/storage
      MINDSDB_DB_SERVICE_HOST: postgres
      MINDSDB_DB_SERVICE_PORT: 5432
      MINDSDB_DB_SERVICE_USER: ${POSTGRES_USER:-postgres}
      MINDSDB_DB_SERVICE_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      MINDSDB_DB_SERVICE_DATABASE: mindsdb
    ports:
      - "47334:47334"
      - "47335:47335"
      - "47336:47336"
    volumes:
      - mindsdb_storage:/mindsdb/storage
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:47334/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
    labels:
      com.flexstack.profile: "ai,data"
      com.flexstack.priority: "3"

# =============================================================================
# IDENTITY & SECURITY (Profile: identity, full)
# Authentication, authorization, and secrets management
# =============================================================================

  # ---------------------------------------------------------------------------
  # Step-CA - Certificate Authority for mTLS
  # ---------------------------------------------------------------------------
  step-ca:
    image: smallstep/step-ca:0.27.5
    container_name: flexstack-step-ca
    profiles: ["identity", "full"]
    environment:
      DOCKER_STEPCA_INIT_PASSWORD_FILE: /run/secrets/step-ca-password
      DOCKER_STEPCA_INIT_NAME: "FlexStack Development CA"
      DOCKER_STEPCA_INIT_DNS_NAMES: "step-ca,localhost"
      DOCKER_STEPCA_INIT_PROVISIONER_NAME: "admin"
      DOCKER_STEPCA_INIT_SKIP_CONFIRM: "true"
    volumes:
      - ../config/step-ca:/home/step
      - ../config/step-ca/secrets/password.txt:/run/secrets/step-ca-password:ro
    ports:
      - "9443:9000"
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "step", "ca", "health", "--ca-url=https://localhost:9000", "--root=/home/step/pki/root_ca.crt"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 15s
    restart: unless-stopped
    labels:
      com.flexstack.profile: "identity"
      com.flexstack.priority: "1"

  # ---------------------------------------------------------------------------
  # Keycloak - OIDC Identity Provider
  # ---------------------------------------------------------------------------
  keycloak:
    image: quay.io/keycloak/keycloak:26.0
    container_name: flexstack-keycloak
    profiles: ["identity", "full"]
    command: start-dev
    environment:
      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN:-admin}
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD:-changeme}
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak
      KC_DB_USERNAME: ${POSTGRES_USER:-postgres}
      KC_DB_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      KC_HOSTNAME_STRICT: "false"
      KC_HTTP_ENABLED: "true"
      KC_HEALTH_ENABLED: "true"
      KC_METRICS_ENABLED: "true"
    ports:
      - "8082:8080"
      - "8443:8443"
    depends_on:
      postgres:
        condition: service_healthy
      step-ca:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/127.0.0.1/8080;echo -e 'GET /health/ready HTTP/1.1\r\nhost: localhost\r\n\r\n' >&3;timeout --signal=QUIT 1 cat <&3 | grep -q '200 OK'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
    labels:
      com.flexstack.profile: "identity"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # HashiCorp Vault - Secrets Management
  # ---------------------------------------------------------------------------
  vault:
    image: hashicorp/vault:1.18
    container_name: flexstack-vault
    profiles: ["identity", "full"]
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_DEV_ROOT_TOKEN_ID:-root}
      VAULT_DEV_LISTEN_ADDRESS: "0.0.0.0:8200"
      VAULT_ADDR: "http://0.0.0.0:8200"
      VAULT_SKIP_VERIFY: "true"
    ports:
      - "8200:8200"
    volumes:
      - ../config/vault:/vault/config
      - vault_data:/vault/file
    cap_add:
      - IPC_LOCK
    depends_on:
      step-ca:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    labels:
      com.flexstack.profile: "identity"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # Vaultwarden - Password Vault
  # ---------------------------------------------------------------------------
  vaultwarden:
    image: vaultwarden/server:1.32.5
    container_name: flexstack-vaultwarden
    profiles: ["identity", "full"]
    environment:
      SIGNUPS_ALLOWED: "true"
      ADMIN_TOKEN: ${VAULTWARDEN_ADMIN_TOKEN:-changeme}
      WEBSOCKET_ENABLED: "true"
      DATABASE_URL: /data/db.sqlite3
      DOMAIN: "http://localhost:8081"
    ports:
      - "8081:80"
      - "3012:3012"
    volumes:
      - vaultwarden_data:/data
    depends_on:
      step-ca:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/alive"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      com.flexstack.profile: "identity"
      com.flexstack.priority: "3"

# =============================================================================
# DATA SERVICES (Profile: data, full)
# Graph database and data query services
# =============================================================================

  # ---------------------------------------------------------------------------
  # Neo4j - Graph Database
  # ---------------------------------------------------------------------------
  neo4j:
    image: neo4j:5-community
    container_name: flexstack-neo4j
    profiles: ["data", "full"]
    environment:
      NEO4J_AUTH: ${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-changeme}
      NEO4J_server_memory_heap_initial__size: 512m
      NEO4J_server_memory_heap_max__size: 1g
      NEO4J_server_memory_pagecache_size: 512m
      NEO4J_server_bolt_listen__address: 0.0.0.0:7687
      NEO4J_server_http_listen__address: 0.0.0.0:7474
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u ${NEO4J_USER:-neo4j} -p ${NEO4J_PASSWORD:-changeme} 'RETURN 1' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
    labels:
      com.flexstack.profile: "data"
      com.flexstack.priority: "2"

# =============================================================================
# EDGE SERVICES (Profile: edge, full)
# API gateway and agent traffic management
# =============================================================================

  # ---------------------------------------------------------------------------
  # Kong Database
  # ---------------------------------------------------------------------------
  kong-db:
    image: postgres:17.2-alpine
    container_name: flexstack-kong-db
    profiles: ["edge", "full"]
    environment:
      POSTGRES_USER: ${KONG_DB_USER:-kong}
      POSTGRES_PASSWORD: ${KONG_DB_PASSWORD:-changeme}
      POSTGRES_DB: ${KONG_DB_NAME:-kong}
    volumes:
      - kong_db_data:/var/lib/postgresql/data
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${KONG_DB_USER:-kong}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    labels:
      com.flexstack.profile: "edge"
      com.flexstack.priority: "1"

  # ---------------------------------------------------------------------------
  # Kong Migrations
  # ---------------------------------------------------------------------------
  kong-migrations:
    image: kong:3.9.0-alpine
    container_name: flexstack-kong-migrations
    profiles: ["edge", "full"]
    command: kong migrations bootstrap
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-db
      KONG_PG_USER: ${KONG_DB_USER:-kong}
      KONG_PG_PASSWORD: ${KONG_DB_PASSWORD:-changeme}
      KONG_PG_DATABASE: ${KONG_DB_NAME:-kong}
    depends_on:
      kong-db:
        condition: service_healthy
    networks:
      - flexstack-network
    restart: on-failure
    labels:
      com.flexstack.profile: "edge"
      com.flexstack.init: "true"

  # ---------------------------------------------------------------------------
  # Kong Gateway - API Gateway
  # ---------------------------------------------------------------------------
  kong:
    image: kong:3.9.0-alpine
    container_name: flexstack-kong
    profiles: ["edge", "full"]
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-db
      KONG_PG_USER: ${KONG_DB_USER:-kong}
      KONG_PG_PASSWORD: ${KONG_DB_PASSWORD:-changeme}
      KONG_PG_DATABASE: ${KONG_DB_NAME:-kong}
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
      KONG_ADMIN_GUI_URL: http://localhost:8002
      KONG_PROXY_LISTEN: 0.0.0.0:8000, 0.0.0.0:8443 ssl
    ports:
      - "8000:8000"
      - "8443:8443"
      - "8001:8001"
      - "8002:8002"
    depends_on:
      kong-db:
        condition: service_healthy
      kong-migrations:
        condition: service_completed_successfully
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'
        reservations:
          memory: 256M
    labels:
      com.flexstack.profile: "edge"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # AgentGateway - Agent/MCP Traffic Plane
  # ---------------------------------------------------------------------------
  agentgateway:
    image: ${AGENTGATEWAY_IMAGE:-agentgateway/agentgateway:0.2.0}
    container_name: flexstack-agentgateway
    profiles: ["edge", "full"]
    environment:
      AG_CONFIG_FILE: /config/config.yaml
      AG_LOG_LEVEL: ${AG_LOG_LEVEL:-info}
      AG_LOCALAI_URL: http://localai:8080
      AG_KONG_ADMIN_URL: http://kong:8001
      AG_MCP_ENABLED: "true"
    ports:
      - "8090:8090"
      - "8091:8091"
      - "8092:8092"
    volumes:
      - ../config/agentgateway:/config:ro
    depends_on:
      kong:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:8090/health || curl -f http://localhost:8090/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 20s
    restart: unless-stopped
    labels:
      com.flexstack.profile: "edge"
      com.flexstack.priority: "3"

# =============================================================================
# MESSAGING & WORKFLOWS (Profile: messaging, full)
# Event bus and durable workflow orchestration
# =============================================================================

  # ---------------------------------------------------------------------------
  # NATS - High-performance Event Bus
  # ---------------------------------------------------------------------------
  nats:
    image: nats:2.10.24-alpine
    container_name: flexstack-nats
    profiles: ["messaging", "full"]
    command: --config /etc/nats/nats.conf
    ports:
      - "4222:4222"
      - "8222:8222"
      - "6222:6222"
    volumes:
      - nats_data:/data
      - ../config/nats:/etc/nats:ro
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    labels:
      com.flexstack.profile: "messaging"
      com.flexstack.priority: "1"

  # ---------------------------------------------------------------------------
  # Temporal Server - Durable Workflows
  # ---------------------------------------------------------------------------
  temporal:
    image: temporalio/auto-setup:1.26.2
    container_name: flexstack-temporal
    profiles: ["messaging", "full"]
    environment:
      DB: postgresql
      DB_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PWD: ${POSTGRES_PASSWORD:-changeme}
      POSTGRES_SEEDS: postgres
      DYNAMIC_CONFIG_FILE_PATH: config/dynamicconfig/development.yaml
    ports:
      - "7233:7233"
      - "7239:7239"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ../config/temporal:/etc/temporal/config/dynamicconfig
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "temporal", "workflow", "list", "--namespace", "default"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
    labels:
      com.flexstack.profile: "messaging"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # Temporal UI
  # ---------------------------------------------------------------------------
  temporal-ui:
    image: temporalio/ui:2.34.0
    container_name: flexstack-temporal-ui
    profiles: ["messaging", "full"]
    environment:
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_CORS_ORIGINS: http://localhost:3000
    ports:
      - "8088:8080"
    depends_on:
      - temporal
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    labels:
      com.flexstack.profile: "messaging"
      com.flexstack.priority: "3"

# =============================================================================
# AUTOMATION (Profile: automation, full)
# Workflow automation and policy management
# =============================================================================

  # ---------------------------------------------------------------------------
  # n8n - Workflow Automation
  # ---------------------------------------------------------------------------
  n8n:
    image: n8nio/n8n:1.73.1
    container_name: flexstack-n8n
    profiles: ["automation", "full"]
    environment:
      N8N_BASIC_AUTH_ACTIVE: "true"
      N8N_BASIC_AUTH_USER: ${N8N_BASIC_AUTH_USER:-admin}
      N8N_BASIC_AUTH_PASSWORD: ${N8N_BASIC_AUTH_PASSWORD:-changeme}
      N8N_HOST: localhost
      N8N_PORT: 5678
      N8N_PROTOCOL: http
      GENERIC_TIMEZONE: UTC
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgres
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n
      DB_POSTGRESDB_USER: ${POSTGRES_USER:-postgres}
      DB_POSTGRESDB_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      N8N_AI_ENABLED: "true"
    ports:
      - "5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:5678/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'
        reservations:
          memory: 256M
    labels:
      com.flexstack.profile: "automation"
      com.flexstack.priority: "2"

  # ---------------------------------------------------------------------------
  # OPA - Open Policy Agent
  # ---------------------------------------------------------------------------
  opa:
    image: openpolicyagent/opa:0.71.0-rootless
    container_name: flexstack-opa
    profiles: ["automation", "full"]
    command:
      - "run"
      - "--server"
      - "--addr=0.0.0.0:8181"
      - "--log-level=info"
      - "--log-format=json"
      - "/policies"
    ports:
      - "8181:8181"
    volumes:
      - ../config/opa/policies:/policies:ro
    networks:
      - flexstack-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8181/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    labels:
      com.flexstack.profile: "automation"
      com.flexstack.priority: "1"

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  # Core
  postgres_data:
    driver: local
  redis_data:
    driver: local
  minio_data:
    driver: local

  # Observability
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
  tempo_data:
    driver: local
  alertmanager_data:
    driver: local

  # AI/ML
  localai_models:
    driver: local
  localai_images:
    driver: local
  agixt_models:
    driver: local
  agixt_workspace:
    driver: local
  mindsdb_storage:
    driver: local

  # Identity
  vault_data:
    driver: local
  vaultwarden_data:
    driver: local

  # Data
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local

  # Edge
  kong_db_data:
    driver: local

  # Messaging
  nats_data:
    driver: local

  # Automation
  n8n_data:
    driver: local

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  flexstack-network:
    name: flexstack-network
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
